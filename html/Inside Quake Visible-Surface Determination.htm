 
<html>
<head>

<title>Inside Quake: Visible-Surface Determination</title>

</head>
<body lang=EN-US class="Normal" >
<body text= white vLink= orange link= orange  bgColor=black >

<p align="center">


<font face="Arial, Helvetica, sans-serif">Inside Quake: Visible-Surface 
  Determination</font></p>
<p align="center"><font face="Arial, Helvetica, sans-serif">by Michael Abrash</font></p>
<p><font face="Arial, Helvetica, sans-serif"> Years ago, I was working at Video 
  Seven, a now-vanished video adapter manufacturer, helping to develop a VGA clone.  
  The fellow who was designing Video Seven’s VGA chip, Tom Wilson, had worked 
  around the clock for months to make his VGA run as fast as possible, and was 
  confident he had pretty much maxed out its performance.  As Tom was putting 
  the finishing touches on his chip design, however, news came fourth-hand that 
  a competitor, Paradise, had juiced up the performance of the clone they were 
  developing, by putting in a FIFO.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> That was it; there was no information 
  about what sort of FIFO, or how much it helped, or anything else.  Nonetheless, 
  Tom, normally an affable, laid-back sort, took on the wide-awake, haunted look 
  of a man with too much caffeine in him and no answers to show for it, as he 
  tried to figure out, from hopelessly thin information, what Paradise had done.  
  Finally, he concluded that Paradise must have put a write FIFO between the system 
  bus and the VGA, so that when the CPU wrote to video memory, the write immediately 
  went into the FIFO, allowing the CPU to keep on processing instead of stalling 
  each time it wrote to display memory.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> Tom couldn’t spare the gates or 
  the time to do a full FIFO, but he could implement a one-deep FIFO, allowing 
  the CPU to get one write ahead of the VGA.  He wasn’t sure how well it would 
  work, but it was all he could do, so he put it in and taped out the chip.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> The one-deep FIFO turned out to 
  work astonishingly well; for a time, Video Seven’s VGAs were the fastest around, 
  a testament to Tom’s ingenuity and creativity under pressure.  However, the 
  truly remarkable part of this story is that Paradise’s FIFO design turned out 
  to bear not the slightest resemblance to Tom’s, and <u>didn’t work as well</u>.  
  Paradise had stuck a <u>read</u> FIFO between display memory and the video output 
  stage of the VGA, allowing the video output to read ahead, so that when the 
  CPU wanted to access display memory, pixels could come from the FIFO while the 
  CPU was serviced immediately.  That did indeed help performance--but not as 
  much as Tom’s write FIFO.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> What we have here is as neat a parable 
  about the nature of creative design as one could hope to find.  The scrap of 
  news about Paradise’s chip contained almost no actual information, but it forced 
  Tom to push past the limits he had unconsciously set in coming up with his original 
  design.  And, in the end, I think that the single most important element of 
  great design, whether it be hardware or software or any creative endeavor, is 
  precisely what the Paradise news triggered in Tom:  The ability to detect the 
  limits you have built into the way you think about your design, and transcend 
  those limits.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> The problem, of course, is how to 
  go about transcending limits you don’t even know you’ve imposed.  There’s no 
  formula for success, but two principles can stand you in good stead:  simplify, 
  and keep on trying new things.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> Generally, if you find your code 
  getting more complex, you’re fine-tuning a frozen design, and it’s likely you 
  can get more of a speed-up, with less code, by rethinking the design.  A really 
  good design should bring with it a moment of immense satisfaction in which everything 
  falls into place, and you’re amazed at how little code is needed and how all 
  the boundary cases just work properly.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> As for how to rethink the design, 
  do it by pursuing whatever ideas occur to you, no matter how off-the-wall they 
  seem.  Many of the truly brilliant design ideas I’ve heard over the years sounded 
  like nonsense at first, because they didn’t fit my preconceived view of the 
  world.  Often, such ideas are in fact off-the-wall, but just as the news about 
  Paradise’s chip sparked Tom’s imagination, aggressively pursuing seemingly-outlandish 
  ideas can open up new design possibilities for you.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> Case in point:  The evolution of 
  Quake’s 3-D graphics engine.</font></p>
<p><font face="Arial, Helvetica, sans-serif"><b>The toughest 3-D challenge of 
  all</b></font></p>
<p><font face="Arial, Helvetica, sans-serif"> I’ve spent most of my waking hours 
  for the last seven months working on Quake, id Software’s successor to DOOM, 
  and after spending the next three months in much the same way, I expect Quake 
  will be out as shareware around the time you read this.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> In terms of graphics, Quake is to 
  DOOM as DOOM was to its predecessor, Wolfenstein 3D.  Quake adds true, arbitrary 
  3-D (you can look up and down, lean, and even fall on your side), detailed lighting 
  and shadows, and 3-D monsters and players in place of DOOM’s sprites.  Sometime 
  soon, I’ll talk about how all that works, but this month I want to talk about 
  what is, in my book, the toughest 3-D problem of all, visible surface determination 
  (drawing the proper surface at each pixel), and its close relative, culling 
  (discarding non-visible polygons as quickly as possible, a way of accelerating 
  visible surface determination).  In the interests of brevity, I’ll use the abbreviation 
  VSD to mean both visible surface determination and culling from now on.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> Why do I think VSD is the toughest 
  3-D challenge?  Although rasterization issues such as texture mapping are fascinating 
  and important, they are tasks of relatively finite scope, and are being moved 
  into hardware as 3-D accelerators appear; also, they only scale with increases 
  in screen resolution, which are relatively modest.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> In contrast, VSD is an open-ended 
  problem, and there are dozens of approaches currently in use.  Even more significantly, 
  the performance of VSD, done in an unsophisticated fashion, scales directly 
  with scene complexity, which tends to increase as a square or cube function, 
  so this very rapidly becomes the limiting factor in doing realistic worlds.  
  I expect VSD increasingly to be the dominant issue in realtime PC 3-D over the 
  next few years, as 3-D worlds become increasingly detailed.  Already, a good-sized 
  Quake level contains on the order of 10,000 polygons, about three times as many 
  polygons as a comparable DOOM level.</font></p>
<p><font face="Arial, Helvetica, sans-serif"><b>The structure of Quake levels</b></font></p>
<p><font face="Arial, Helvetica, sans-serif"> Before diving into VSD, let me note 
  that each Quake level is stored as a single huge 3-D BSP tree.  This BSP tree, 
  like any BSP, subdivides space, in this case along the planes of the polygons.  
  However, unlike the BSP tree I presented last time, Quake’s BSP tree does not 
  store polygons in the tree nodes, as part of the splitting planes, but rather 
  in the empty (non-solid) leaves, as shown in overhead view in Figure 1.</font></p>
<center>
  <table width="75" border="0">
    <tr> 
      <td><img src="images/fig1.gif" width="509" height="396"></td>
    </tr>
    <tr> 
      <td><font size="2">Figure 1: In Quake, polygons are stored in the empty 
        leaves. Shaded areas are solid leaves (solid volumes, such as the insides 
        of walls).</font></td>
    </tr>
  </table>
  <p align="left"><font face="Arial, Helvetica, sans-serif"> Correct drawing order 
    can be obtained by drawing the leaves in front-to-back or back-to-front BSP 
    order, again as discussed last time.  Also, because BSP leaves are always 
    convex and the polygons are on the boundaries of the BSP leaves, facing inward, 
    the polygons in a given leaf can never obscure one another and can be drawn 
    in any order.  (This is a general property of convex polyhedra.)</font></p>
</center>
<p><font face="Arial, Helvetica, sans-serif"><b>Culling and visible surface determination</b></font></p>
<p><font face="Arial, Helvetica, sans-serif"> The process of VSD would ideally 
  work as follows.  First, you would cull all polygons that are completely outside 
  the view frustum (view pyramid), and would clip away the irrelevant portions 
  of any polygons that are partially outside.  Then you would draw only those 
  pixels of each polygon that are actually visible from the current viewpoint, 
  as shown in overhead view in Figure 2, wasting no time overdrawing pixels multiple 
  times; note how little of the polygon set in Figure 2 actually need to be drawn.  
  Finally, in a perfect world, the tests to figure out what parts of which polygons 
  are visible would be free, and the processing time would be the same for all 
  possible viewpoints, giving the game a smooth visual flow.</font></p>
<center>
  <table width="75" border="0">
    <tr> 
      <td><img src="images/fig2.gif" width="430" height="350"></td>
    </tr>
    <tr> 
      <td><font size="2">Figure 2: An ideal VSD architecture would draw only visible 
        parts of visible polygons.</font></td>
    </tr>
  </table>
</center>
<p align="center">&nbsp;</p>
<p><font face="Arial, Helvetica, sans-serif"> As it happens, it is easy to determine 
  which polygons are outside the frustum or partially clipped, and it’s quite 
  possible to figure out precisely which pixels need to be drawn.  Alas, the world 
  is far from perfect, and those tests are far from free, so the real trick is 
  how to accelerate or skip various tests and still produce the desired result.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> As I discussed at length last time, 
  given a BSP, it’s easy and inexpensive to walk the world in front-to-back or 
  back-to-front order.  The simplest VSD solution, which I in fact demonstrated 
  last time, is to simply walk the tree back-to-front, clip each polygon to the 
  frustum, and draw it if it’s facing forward and not entirely clipped (the painter’s 
  algorithm).  Is that an adequate solution?</font></p>
<p><font face="Arial, Helvetica, sans-serif"> For relatively simple worlds, it 
  is perfectly acceptable.  It doesn’t scale very well, though.  One problem is 
  that as you add more polygons in the world, more transformations and tests have 
  to be performed to cull polygons that aren’t visible; at some point, that will 
  bog performance down considerably.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> Happily, there’s a good workaround 
  for this particular problem.  As discussed earlier, each leaf of a BSP tree 
  represents a convex subspace, with the nodes that bound the leaf delimiting 
  the space.  Perhaps less obvious is that each node in a BSP tree also describes 
  a subspace--the subspace composed of all the node’s children, as shown in Figure 
  3.  Another way of thinking of this is that each node splits into two pieces 
  the subspace created by the nodes above it in the tree, and the node’s children 
  then further carve that subspace into all the leaves that descend from the node.</font></p>
<center>
  <table width="75" border="0">
    <tr> 
      <td><img src="images/fig3.gif" width="443" height="257"></td>
    </tr>
    <tr> 
      <td><font size="2">Figure 3: Node E describes the shaded subspace, which 
        contains leaves 5, 6, and 7, and node F.</font></td>
    </tr>
  </table>
</center>
<p align="center">&nbsp;</p>
<p><font face="Arial, Helvetica, sans-serif"> Since a node’s subspace is bounded 
  and convex, it is possible to test whether it is entirely outside the frustum.  
  If it is, <u>all</u> of the node’s children are certain to be fully clipped, 
  and can be rejected without any additional processing.  Since most of the world 
  is typically outside the frustum, many of the polygons in the world can be culled 
  almost for free, in huge, node-subspace chunks.  It’s relatively expensive to 
  perform a perfect test for subspace clipping, so instead bounding spheres or 
  boxes are often maintained for each node, specifically for culling tests.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> So culling to the frustum isn’t 
  a problem, and the BSP can be used to draw back to front.  What’s the problem?</font></p>
<p><font face="Arial, Helvetica, sans-serif"><b>Overdraw</b></font></p>
<p><font face="Arial, Helvetica, sans-serif"> The problem John Carmack, the driving 
  technical force behind DOOM and Quake, faced when he designed Quake was that 
  in a complex world, many scenes have an awful lot of polygons in the frustum.  
  Most of those polygons are partially or entirely obscured by other polygons, 
  but the painter’s algorithm described above requires that every pixel of every 
  polygon in the frustum be drawn, often only to be overdrawn.  In a 10,000-polygon 
  Quake level, it would be easy to get a worst-case overdraw level of 10 times 
  or more; that is, in some frames each pixel could be drawn 10 times or more, 
  on average.  No rasterizer is fast enough to compensate for an order of magnitude 
  more work than is actually necessary to show a scene; worse still, the painter’s 
  algorithm will cause a vast difference between best-case and worst-case performance, 
  so the frame rate can vary wildly as the viewer moves around.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> So the problem John faced was how 
  to keep overdraw down to a manageable level, preferably drawing each pixel exactly 
  once, but certainly no more than two or three times in the worst case.  As with 
  frustum culling, it would be ideal if he could eliminate all invisible polygons 
  in the frustum with virtually no work.  It would also be a plus if he could 
  manage to draw only the visible parts of partially-visible polygons, but that 
  was a balancing act, in that it had to be a lower-cost operation than the overdraw 
  that would otherwise result.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> When I arrived at id at the beginning 
  of March, John already had an engine prototyped and a plan in mind, and I assumed 
  that our work was a simple matter of finishing and optimizing that engine.  
  If I had been aware of id’s history, however, I would have known better.  John 
  had done not only DOOM, but also the engines for Wolf 3D and several earlier 
  games, and had actually done several different versions of each engine in the 
  course of development (once doing four engines in four weeks), for a total of 
  perhaps 20 distinct engines over a four-year period.  John’s tireless pursuit 
  of new and better designs for Quake’s engine, from every angle he could think 
  of, would end only when we shipped.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> By three months after I arrived, 
  only one element of the original VSD design was anywhere in sight, and John 
  had taken “try new things” farther than I’d ever seen it taken.</font></p>
<p><font face="Arial, Helvetica, sans-serif"><b>The beam tree</b></font></p>
<p><font face="Arial, Helvetica, sans-serif"> John’s original Quake design was 
  to draw front to back, using a second BSP tree to keep track of what parts of 
  the screen were already drawn and which were still empty and therefore drawable 
  by the remaining polygons.  Logically, you can think of this BSP tree as being 
  a 2-D region describing solid and empty areas of the screen, as shown in Figure 
  4, but in fact it is a 3-D tree, of the sort known as a beam tree.  A beam tree 
  is a collection of 3-D wedges (beams), bounded by planes, projecting out from 
  some center point, in this case the viewpoint, as shown in Figure 5.</font></p>
<center>
  <table width="75" border="0">
    <tr> 
      <td><img src="images/fig4.gif" width="474" height="246"></td>
    </tr>
    <tr> 
      <td><font size="2">Figure 4: Quake's beam tree effectively partitioned the 
        screen into 2-D regions.</font></td>
    </tr>
  </table>
</center>
<p align="center"><font face="Arial, Helvetica, sans-serif"><br>
  </font></p>
<center>
  <table width="75" border="0">
    <tr> 
      <td><img src="images/fig5.gif" width="268" height="199"></td>
    </tr>
    <tr> 
      <td><font size="2">Figure 5: Quake's beam tree was composed of 3-D wedges, 
        or beams, projecting out from the viewpoint to polygon edges.</font></td>
    </tr>
  </table>
</center>
<p align="center">&nbsp; </p>
<p><font face="Arial, Helvetica, sans-serif"> In John’s design, the beam tree 
  started out consisting of a single beam describing the frustum; everything outside 
  that beam was marked solid (so nothing would draw there), and the inside of 
  the beam was marked empty.  As each new polygon was reached while walking the 
  world BSP tree front to back, that polygon was converted to a beam by running 
  planes from its edges through the viewpoint, and any part of the beam that intersected 
  empty beams in the beam tree was considered drawable and added to the beam tree 
  as a solid beam.  This continued until either there were no more polygons or 
  the beam tree became entirely solid.  Once the beam tree was completed, the 
  visible portions of the polygons that had contributed to the beam tree were 
  drawn.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> The advantage to working with a 
  3-D beam tree, rather than a 2-D region, is that determining which side of a 
  beam plane a polygon vertex is on involves only checking the sign of the dot 
  product of the ray to the vertex and the plane normal, because all beam planes 
  run through the origin (the viewpoint).  Also, because a beam plane is completely 
  described by a single normal, generating a beam from a polygon edge requires 
  only a cross-product of the edge and a ray from the edge to the viewpoint.  
  Finally, bounding spheres of BSP nodes can be used to do the aforementioned 
  bulk culling to the frustum.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> The early-out feature of the beam 
  tree--stopping when the beam tree becomes solid--seems appealing, because it 
  appears to cap worst-case performance.  Unfortunately, there are still scenes 
  where it’s possible to see all the way to the sky or the back wall of the world, 
  so in the worst case, all polygons in the frustum will still have to be tested 
  against the beam tree.  Similar problems can arise from tiny cracks due to numeric 
  precision limitations.  Beam tree clipping is fairly time-consuming, and in 
  scenes with long view distances, such as views across the top of a level, the 
  total cost of beam processing slowed Quake’s frame rate to a crawl.  So, in 
  the end, the beam-tree approach proved to suffer from much the same malady as 
  the painter’s algorithm: The worst case was much worse than the average case, 
  and it didn’t scale well with increasing level complexity.</font></p>
<p><font face="Arial, Helvetica, sans-serif"><b>3-D engine <u>du jour</u></b></font></p>
<p><font face="Arial, Helvetica, sans-serif"> Once the beam tree was working, 
  John relentlessly worked at speeding up the 3-D engine, always trying to improve 
  the design, rather than tweaking the implementation.  At least once a week, 
  and often every day, he would walk into my office and say “Last night I couldn’t 
  get to sleep, so I was thinking...” and I’d know that I was about to get my 
  mind stretched yet again.  John tried many ways to improve the beam tree, with 
  some success, but more interesting was the profusion of wildly different approaches 
  that he generated, some of which were merely discussed, others of which were 
  implemented in overnight or weekend-long bursts of coding, in both cases ultimately 
  discarded or further evolved when they turned out not to meet the design criteria 
  well enough.  Here are some of those approaches, presented in minimal detail 
  in the hopes that, like Tom Wilson with the Paradise FIFO, your imagination 
  will be sparked.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> Subdividing raycast:  Rays are cast 
  in an 8x8 screen-pixel grid; this is a highly efficient operation because the 
  first intersection with a surface can be found by simply clipping the ray into 
  the BSP tree, starting at the viewpoint, until a solid leaf is reached.  If 
  adjacent rays don’t hit the same surface, then a ray is cast halfway between, 
  and so on until all adjacent rays either hit the same surface or are on adjacent 
  pixels; then the block around each ray is drawn from the polygon that was hit.  
  This scales very well, being limited by the number of pixels, with no overdraw.  
  The problem is dropouts; it’s quite possible for small polygons to fall between 
  rays and vanish.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> Vertex-free surfaces:  The world 
  is represented by a set of surface planes.  The polygons are implicit in the 
  plane intersections, and are extracted from the planes as a final step before 
  drawing.  This makes for fast clipping and a very small data set (planes are 
  far more compact than polygons), but it’s time-consuming to extract polygons 
  from planes.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> Draw-buffer:  Like a z-buffer, but 
  with 1 bit per pixel, indicating whether the pixel has been drawn yet.  This 
  eliminates overdraw, but at the cost of an inner-loop buffer test, extra writes 
  and cache misses, and, worst of all, considerable complexity.  Variations are 
  testing the draw-buffer a byte at a time and completely skipping fully-occluded 
  bytes, or branching off each draw-buffer byte to one of 256 unrolled inner loops 
  for drawing 0-8 pixels, in the process possibly taking advantage of the ability 
  of the x86 to do the perspective floating-point divide in parallel while 8 pixels 
  are processed.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> Span-based drawing:  Polygons are 
  rasterized into spans, which are added to a global span list and clipped against 
  that list so that only the nearest span at each pixel remains.  Little sorting 
  is needed with front-to-back walking, because if there’s any overlap, the span 
  already in the list is nearer.  This eliminates overdraw, but at the cost of 
  a lot of span arithmetic; also, every polygon still has to be turned into spans.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> Portals:  the holes where polygons 
  are missing on surfaces are tracked, because it’s only through such portals 
  that line-of-sight can extend.  Drawing goes front-to-back, and when a portal 
  is encountered, polygons and portals behind it are clipped to its limits, until 
  no polygons or portals remain visible.  Applied recursively, this allows drawing 
  only the visible portions of visible polygons, but at the cost of a considerable 
  amount of portal clipping.</font></p>
<p><font face="Arial, Helvetica, sans-serif"><b>Breakthrough</b></font></p>
<p><font face="Arial, Helvetica, sans-serif"> In the end, John decided that the 
  beam tree was a sort of second-order structure, reflecting information already 
  implicitly contained in the world BSP tree, so he tackled the problem of extracting 
  visibility information directly from the world BSP tree.  He spent a week on 
  this, as a byproduct devising a perfect DOOM (2-D) visibility architecture, 
  whereby a single, linear walk of a DOOM BSP tree produces zero-overdraw 2-D 
  visibility.  Doing the same in 3-D turned out to be a much more complex problem, 
  though, and by the end of the week John was frustrated by the increasing complexity 
  and persistent glitches in the visibility code.  Although the direct-BSP approach 
  was getting closer to working, it was taking more and more tweaking, and a simple, 
  clean design didn’t seem to be falling out.  When I left work one Friday, John 
  was preparing to try to get the direct-BSP approach working properly over the 
  weekend.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> When I came in on Monday, John had 
  the look of a man who had broken through to the other side--and also the look 
  of a man who hadn’t had much sleep.  He had worked all weekend on the direct-BSP 
  approach, and had gotten it working reasonably well, with insights into how 
  to finish it off.  At 3:30 AM Monday morning, as he lay in bed, thinking about 
  portals, he thought of precalculating and storing in each leaf a list of all 
  leaves visible from that leaf, and then at runtime just drawing the visible 
  leaves back-to-front for whatever leaf the viewpoint happens to be in, ignoring 
  all other leaves entirely.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> Size was a concern; initially, a 
  raw, uncompressed potentially visible set (PVS) was several megabytes in size.  
  However, the PVS could be stored as a bit vector, with 1 bit per leaf, a structure 
  that shrunk a great deal with simple zero-byte compression.  Those steps, along 
  with changing the BSP heuristic to generate fewer leaves (contrary to what I 
  said a few months back, choosing as the next splitter the polygon that splits 
  the fewest other polygons is clearly the best heuristic, based on the latest 
  data) and sealing the outside of the levels so the BSPer can remove the outside 
  surfaces, which can never be seen, eventually brought the PVS down to about 
  20 Kb for a good-size level.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> In exchange for that 20 Kb, culling 
  leaves outside the frustum is speeded up (because only leaves in the PVS are 
  considered), and culling inside the frustum costs nothing more than a little 
  overdraw (the PVS for a leaf includes all leaves visible from anywhere in the 
  leaf, so some overdraw, typically on the order of 50% but ranging up to 150%, 
  generally occurs).  Better yet, precalculating the PVS results in a leveling 
  of performance; worst case is no longer much worse than best case, because there’s 
  no longer extra VSD processing--just more polygons and perhaps some extra overdraw--associated 
  with complex scenes.  The first time John showed me his working prototype, I 
  went to the most complex scene I knew of, a place where the frame rate used 
  to grind down into the single digits, and spun around smoothly, with no perceptible 
  slowdown.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> John says precalculating the PVS 
  was a logical evolution of the approaches he had been considering, that there 
  was no moment when he said “Eureka!”.  Nonetheless, it was clearly a breakthrough 
  to a brand-new, superior design, a design that, together with a still-in-development 
  sorted-edge rasterizer that completely eliminates overdraw, comes remarkably 
  close to meeting the “perfect-world” specifications we laid out at the start.</font></p>
<p><font face="Arial, Helvetica, sans-serif"><b>Simplify, and keep on trying new 
  things</b></font></p>
<p><font face="Arial, Helvetica, sans-serif"> What does it all mean?  Exactly 
  what I said up front:  Simplify, and keep trying new things.  The precalculated 
  PVS is simpler than any of the other schemes that had been considered (although 
  precalculating the PVS is an interesting task that I’ll discuss another time).  
  In fact, at runtime the precalculated PVS is just a constrained version of the 
  painter’s algorithm.  Does that mean it’s not particularly profound?</font></p>
<p><font face="Arial, Helvetica, sans-serif"> Not at all.  All really great designs 
  seem simple and even obvious--once they’ve been designed.  But the process of 
  getting there requires incredible persistence, and a willingness to try lots 
  of different ideas until the right one falls into place, as happened here.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> My friend Chris Hecker has a theory 
  that all approaches work out to the same thing in the end, since they all reflect 
  the same underlying state and functionality.  In terms of underlying theory, 
  I’ve found that to be true; whether you do perspective texture mapping with 
  a divide or with incremental hyperbolic calculations, the numbers do exactly 
  the same thing.  When it comes to implementation, however, my experience is 
  that simply time-shifting an approach, or matching hardware capabilities better, 
  or caching can make an astonishing difference.  My friend Terje Mathisen likes 
  to say that “almost all programming can be viewed as an exercise in caching,” 
  and that’s exactly what John did.  No matter how fast he made his VSD calculations, 
  they could never be as fast as precalculating and looking up the visibility, 
  and his most inspired move was to yank himself out of the “faster code” mindset 
  and realize that it was in fact possible to precalculate (in effect, cache) 
  and look up the PVS.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> The hardest thing in the world is 
  to step outside a familiar, pretty good solution to a difficult problem and 
  look for a different, better solution.  The best ways I know to do that are 
  to keep trying new, wacky things, and always, always, always try to simplify.  
  One of John’s goals is to have fewer lines of code in each 3-D game than in 
  the previous game, on the assumption that as he learns more, he should be able 
  to do things better with less code.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> So far, it seems to have worked 
  out pretty well for him.</font></p>
<p><font face="Arial, Helvetica, sans-serif"><b>Learn now, pay forward</b></font></p>
<p><font face="Arial, Helvetica, sans-serif"> There’s one other thing I’d like 
  to mention before I close up shop for this month.  As far back as I can remember, 
  <u>DDJ</u> has epitomized the attitude that sharing programming information 
  is A Good Thing.  I know a lot of programmers who were able to leap ahead in 
  their development because of Hendrix’s Tiny C, or Stevens’ D-Flat, or simply 
  by browsing through <u>DDJ</u>’s annual collections.  (Me, for one.)  Most companies 
  understandably view sharing information in a very different way, as potential 
  profit lost--but that’s what makes <u>DDJ</u> so valuable to the programming 
  community.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> It is in that spirit that id Software 
  is allowing me to describe in these pages how Quake works, even before Quake 
  has shipped.  That’s also why id has placed the full source code for Wolfenstein 
  3D on ftp.idsoftware.com/idstuff/source; you can’t just recompile the code and 
  sell it, but you can learn how a full-blown, successful game works; check wolfsrc.txt 
  in the above-mentioned directory for details on how the code may be used.</font></p>
<p><font face="Arial, Helvetica, sans-serif"> So remember, when it’s legally possible, 
  sharing information benefits us all in the long run.  You can pay forward the 
  debt for the information you gain here and elsewhere by sharing what you know 
  whenever you can, by writing an article or book or posting on the Net.  None 
  of us learns in a vacuum; we all stand on the shoulders of giants such as Wirth 
  and Knuth and thousands of others.  Lend your shoulders to building the future!</font></p>
<p><font face="Arial, Helvetica, sans-serif"><b>References</b></font></p>
<p><font face="Arial, Helvetica, sans-serif">Foley, James D., <u>et al.</u>, <u>Computer 
  Graphics:  Principles and Practice</u>, Addison Wesley, 1990, ISBN 0-201-12110-7 
  (beams, BSP trees, VSD).</font></p>
<p><font face="Arial, Helvetica, sans-serif">Teller, Seth, <u>Visibility Computations 
  in Densely Occluded Polyhedral Environments</u> (dissertation), available on</font></p>
<p><font face="Arial, Helvetica, sans-serif">http://theory.lcs.mit.edu/~seth/</font></p>
<p><font face="Arial, Helvetica, sans-serif">along with several other papers relevant 
  to visibility determination.</font></p>
<p><font face="Arial, Helvetica, sans-serif">Teller, Seth, <u>Visibility Preprocessing 
  for Interactive Walkthroughs</u>, SIGGRAPH 91 proceedings, pp. 61-69.</font></p>
<p>&nbsp;</p>
<p>&lt;&lt; <a href="contents.html" target="_self"><font face="Arial, Helvetica, sans-serif">Back 
  to contents</font></a></p>
</body>
</html>

